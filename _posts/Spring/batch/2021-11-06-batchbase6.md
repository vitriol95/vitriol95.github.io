---
title: 스프링 배치 - 6 ItemReader
date: 2021-11-06 12:00:00 +0900
categories: [Spring,batch]
tags: [spring,springboot,batch]
---

# ItemReader

이전시간에 청크 지향방식 태스크에 대해 이야기를 해보았는데, 총 3가지 과정으로 나누어지는 것을 확인했다. 이번엔 이중 `Reader`에 대해 좀 더 들어가보자.

## 기본 개념

다양한 입력으로부터 데이터를 읽어 제공하는 인터페이스에 해당한다. 지원하는 종류는 다음과 같다.

- FlatFile (csv,txt)
- XML, JSON
- **DataBase**
- JMS, RabbitMQ 같은 MQ
- Custom Reader

일종의 큰 맥락을 보면 아래 그림과 같이 정리된다.

<img src="/assets/img/batch/20.png">

굉장히 방대하고 양도 많다.. 여기서 `ItemReader<T>`는 `read()`메서드 하나를 가지고있으며 `ItemStream` 인터페이스는 스트림을 열고 닫으며 업데이트하는 핸들러들을 제공한다.

<br/>

다수의 구현체들이 두가지 인터페이스를 모두 구현하고 있으며 앞서 지원한 파일형태나 DB에 연결하기 위한 커넥션, 스트림열기, 입력장치 초기화등을 모두 지원한다. 이들중 우리가 눈여겨 보아야할 것은 두개가 존재한다

- `****CursorItemReader`
- `****PagingItemReader` 

이 두가지 Reader가 이번 주제의 메인 디쉬가 될 것이다.

## AbstractItemCountingItemStreamReader

앞선 포스트에서 `ChunkProvider`를 보면, 결국 마지막에는 등록한 ItemReader에게 read작업을 위임해주고 있다. 이 ItemReader의 종류에 따라 읽는 방식이 달라진다는 것을 의미하는데, 이중 쓰이는 대표적인 추상클래스중 하나인 `AbstractItemCountingItemStreamReader`를 살펴볼 것이다.
> 앞선 그림 계층도를 보면 우리가 쓸 대부분의 클래스들이 해당 추상클래스를 구현하고 있다. 따라서 기본 동작구조를 알아볼 생각이다.

```java
public abstract class AbstractItemCountingItemStreamItemReader<T> extends AbstractItemStreamItemReader<T> {

	// ... 
	private int currentItemCount = 0;
	private int maxItemCount = Integer.MAX_VALUE;

    @Nullable
	@Override
	public T read() throws Exception, UnexpectedInputException, ParseException {
		if (currentItemCount >= maxItemCount) {
			return null;
		}
		currentItemCount++;
		T item = doRead();
		if(item instanceof ItemCountAware) {
			((ItemCountAware) item).setItemCount(currentItemCount);
		}
		return item;
	}

    @Nullable
	protected abstract T doRead() throws Exception;
```

템플릿 메서드 패턴처럼 `doRead()`는 구현체에게 넘기고있다. 이제 읽는 2가지 방식을 알아보고 대표적인 구체클래스들로 넘어가보자.

## Cursor vs Paging

<img src="/assets/img/batch/21.png">

대표적인 DB ItemReader로는 **Cursor Based**와 **Paging Based**가 존재한다. 여기서 `PageSize`와 `ChunkSize`는 서로 의미하는 것이 다르다는 것을 알아야한다.

- `ChunkSize`는 한번에 처리될 트랜잭션의 단위를 의미하며
- `PageSize`는 한번에 조회할 Item의 양을 의미한다. 
> 따라서 하나의 청크 안에서도 여러 페이지가 존재할 수 있다.

가장먼저, Cursor로 작동하는 대표적인 Reader인 `JdbcCusorItemReader<T>`를 살펴볼 것이다.

## CusorItemReader

### JdbcCursorItemReader

계층도를 살펴보니 `AbstractCursorItemReader<T>`를 상속하고 있다. 이를 먼저 확인해야겠다. `doRead()`메서드를 기준으로 보면된다.

```java
public abstract class AbstractCursorItemReader<T> extends AbstractItemCountingItemStreamItemReader<T>
implements InitializingBean {
    
    //...

	@Override
	protected T doRead() throws Exception {
		if (rs == null) {
			throw new ReaderNotOpenException("Reader must be open before it can be read.");
		}

		try {
			if (!rs.next()) {
				return null;
			}
			int currentRow = getCurrentItemCount();
			T item = readCursor(rs, currentRow);
			verifyCursorPosition(currentRow);
			return item;
		}
		catch (SQLException se) {
			throw getExceptionTranslator().translate("Attempt to process next row failed", getSql(), se);
		}
	}

	protected abstract T readCursor(ResultSet rs, int currentRow) throws SQLException;
}
```

rs(ResultSet)을 기준으로 `next()`를 호출하여 다음 튜플을 확인하고 커서를 옮기어 `currentRow`를 하나씩 가져오고 있음을 알 수 있다. 그리고 `readCursor()`메서드를 세부 구현체에 넘기고 있다. 

<br/>

이외에도 코드엔 포함되지 않았지만 해당 클래스는 많은 일을 해준다. ItemStream의 메서드들(`doOpen()`,`doClose()`) 등을 구현하여 커넥션에 대한 기초작업또한 진행해준다. 이제 `JdbcCusorItemReader`를 만나러 가보자.

```java
public class JdbcCursorItemReader<T> extends AbstractCursorItemReader<T>{
    // ...

	@Override
	protected T readCursor(ResultSet rs, int currentRow) throws SQLException {
		return rowMapper.mapRow(rs, currentRow);
	}

}
```

생각보다 정말 단순하다. `readCursor()`는 **rowMapper**를 이용해 설정한 지네릭타입으로 값을 리턴해주고있었다. 앞선 코드와 함께 보면 유기적으로 이해가 될 것이다.

### 예시코드 

```java
@Bean
public ItemReader<Customer> customItemReader() {
    return new JdbcCursorItemReaderBuilder<Customer>()
            .name("jdbcCursorItemReader")
            .fetchSize(chunk_size)
            .sql("select id, firstName, lastName, birthdate from customer where firstName like ? order by lastName, firstName")
            .beanRowMapper(Customer.class)
            .queryArguments("A%")
            .dataSource(dataSource)
            .build();
}
```
다음은 `JdbcCursorItemReader`를 이용해 구현해본 ItemReader에 해당한다. 여기서 `fetchSize`는 청크사이즈와 같게해야하며, 리턴타입 및 sql등을 줄 수 있다.
> fetchSize는 메모리에 올려둘 사이즈에 해당한다. 대부분은 청크사이즈와 크기를 동일시하여 설정한다.

### JpaCursorItemReader

<img src="/assets/img/batch/22.png">

앞선 Jdbc와 별다를 것은 없다. 하지만, Jpa의 경우 `EntityManager`기반으로 일종의 상태관리를 진행하므로 이에대한 설정들이 포함되어있다. 내부적으로 동작하는 것은 Jdbc기반이므로 똑같다.

```java
@Bean
public ItemReader<Customer> customItemReader() {

    Map<String, Object> params = new HashMap<>();
    params.put("firstName", "A%");

    return new JpaCursorItemReaderBuilder<Customer>()
            .name("jpaCursorItemBuilder")
            .entityManagerFactory(emf)
            .queryString("select c from Customer c where firstname like :firstname")
            .parameterValues(params)
            .build();
}
```

이처럼 `.entityManagerFactory()`를 따로 설정해주면 되며, sql의 경우 JPQL을 사용해도 된다!

## PagingItemReader

이제 Paging차례이다. 가장 먼저 기본이 되는 `AbstractPagingItemReader<T>`를 살펴보는 것부터 시작해보자.

```java
public abstract class AbstractPagingItemReader<T> extends AbstractItemCountingItemStreamItemReader<T> 
        implements InitializingBean {

    @Nullable
	@Override
	protected T doRead() throws Exception {

		synchronized (lock) {

			if (results == null || current >= pageSize) {
				if (logger.isDebugEnabled()) {
					logger.debug("Reading page " + getPage());
				}

				doReadPage();
				page++;
				if (current >= pageSize) {
					current = 0;
				}

			}

			int next = current++;
			if (next < results.size()) {
				return results.get(next);
			}
			else {
				return null;
			}

		}

	}

	abstract protected void doReadPage();
}
```

뭔가 재밌는걸 눈치 챘을 것이다. 바로 `synchronized()`로 블록처리가 되어 동시성제어를 진행하고 있다는 것이다. 해당 메서드 외에도 여러 구체메서드에는 `synchronized()`가 걸려있기에 Thread 안정성을 보장해주고 있다.

<br/>

이후, 실제 읽어오는 부분은 `doReadPage()`로 구체 클래스에게 맡기고있다.

### JdbcPagingItemReader

```java
public class JdbcPagingItemReader<T> extends AbstractPagingItemReader<T> implements InitializingBean {
    @Override
	@SuppressWarnings("unchecked")
	protected void doReadPage() {
		if (results == null) {
			results = new CopyOnWriteArrayList<>();
		}
		else {
			results.clear();
		}

		PagingRowMapper rowCallback = new PagingRowMapper();

		List<?> query;

		if (getPage() == 0) {
			if (logger.isDebugEnabled()) {
				logger.debug("SQL used for reading first page: [" + firstPageSql + "]");
			}
			if (parameterValues != null && parameterValues.size() > 0) {
				if (this.queryProvider.isUsingNamedParameters()) {
					query = namedParameterJdbcTemplate.query(firstPageSql,
							getParameterMap(parameterValues, null), rowCallback);
				}
				else {
					query = getJdbcTemplate().query(firstPageSql,
							getParameterList(parameterValues, null).toArray(), rowCallback);
				}
			}
			else {
				query = getJdbcTemplate().query(firstPageSql, rowCallback);
			}

		}
		else {
			previousStartAfterValues = startAfterValues;
			if (logger.isDebugEnabled()) {
				logger.debug("SQL used for reading remaining pages: [" + remainingPagesSql + "]");
			}
			if (this.queryProvider.isUsingNamedParameters()) {
				query = namedParameterJdbcTemplate.query(remainingPagesSql,
						getParameterMap(parameterValues, startAfterValues), rowCallback);
			}
			else {
				query = getJdbcTemplate().query(remainingPagesSql,
						getParameterList(parameterValues, startAfterValues).toArray(), rowCallback);
			}
		}

		Collection<T> result = (Collection<T>) query;
		results.addAll(result);
	}
}
```

위 흐름을 좀 더 깔끔한 그림으로 정리해보면 다음과 같다.

<img src="/assets/img/batch/23.png">

`JdbcTemplate`를 이용하여 resultSet의 페이지크기만큼 가져와 이를 돌려주고 있는 방식이다.
> 사실 코드 읽는것이 좀 어려웠다.. 직접 사용처에서 코드를 보자.

### 예시코드

```java
@Bean
public JdbcPagingItemReader<Customer> pagingItemReader() {
    Map<String, Object> params = new HashMap<>();
    params.put("firstname","Rose");

    return new JdbcPagingItemReaderBuilder<Customer>()
        .pageSize(100)
        .fetchSize(100)
        .dataSource(dataSource)
        .rowMapper(new BeanPropertyRowMapper<>(Customer.class))
        .queryProvider(createQueryProvider())
        .parameterValues(params)
        .name("myJdbcPageReader")
        .build();
}

@Bean
public PagingQueryProvider createQueryProvider(){
    SqlPagingProviderFactoryBean queryProvider = new SqlPagingProviderFactoryBean();
    queryProvider.setDataSource(dataSource);
    queryProvider.setSelectClause("id, firstname, lastName, birthdate");
    queryProvider.setFromClause("from customer");
    queryProvider.setWhereClause("where firstname >= :firstname");

    Map<String,Order> sortKeys = new HashMap<>(1);
    sortKeys.put("id",Order.ASCENDING);

    qeuryProvider.setSortKeys(sortKeys);

    return queryProvider.getObject();
}
```

`.queryProvider()` API를 이용하여 좀 더 쉽게 쿼리를 처리해주는 기능도 제공하니 편리하다. 여기서는 페이지 사이즈와 청크사이즈를 같게하여 진행했는데, 이는 꼭 필수사항은 아니다.
> 하지만 Jpa를 사용할땐 주의해야한다. 이는 나중에 설명하겠다.

위 설정으로 Read를 진행한다면 다음과 같은 쿼리가 나갈 것이다.

```sql
SELECT id, firstname, lastname, birthdate
FROM customer
WHERE firstname >= 'Rose'
ORDER BY id ASC LIMIT 100
```

그리고 dataSource를 등록해주고 있는것을 확인할 수 있는데, 이는 당연한것인게 DB 별로 페이징 쿼리가 다르기 때문이다. (Oracle, MySQL 등등..) 해당 Reader는 이런 DB종류에 따른 페이징 쿼리를 맞게 짜준다.

### JpaPagingItemReader

Jdbc보다 코드 읽는게 쉬워서 해당 클래스의 `doRead()`를 보며 흐름을 파악하는게 더 수월했다.

```java
protected void doReadPage() {

		EntityTransaction tx = null;
		
		if (transacted) {
			tx = entityManager.getTransaction();
			tx.begin();
			
			entityManager.flush();
			entityManager.clear();
		}

		Query query = createQuery().setFirstResult(getPage() * getPageSize()).setMaxResults(getPageSize());

		if (parameterValues != null) {
			for (Map.Entry<String, Object> me : parameterValues.entrySet()) {
				query.setParameter(me.getKey(), me.getValue());
			}
		}

		if (results == null) {
			results = new CopyOnWriteArrayList<>();
		}
		else {
			results.clear();
		}
		
		if (!transacted) {
			List<T> queryResult = query.getResultList();
			for (T entity : queryResult) {
				entityManager.detach(entity);
				results.add(entity);
			}
		} else {
			results.addAll(query.getResultList());
			tx.commit();
		}
	}
```

`Query query = createQuery().setFirstResult(getPage() * getPageSize()).setMaxResults(getPageSize());` 부분을 보면 Page만큼 추가 조회를 하는것을 알 수 있고, `results.addAll(query.getResultList());`를 통해 청크안에 페이지단위로 아이템을 집어넣어준다.

## 추가 이슈

PageSize와 ChunkSize가 다른경우도 존재할 수 있다. 만약 후자가 100이고, 전자가 10이라면 `ItemReader`에서 Page조회가 10번 일어나야 한번의 트랜잭션이 발생해 Chunk처리가 된다.

<br/>

이렇게 한번의 트랜잭션 처리를 위해서 10번의 조회하는 쿼리가 발생하기에 성능이슈가 일어날 수 있다. 따라서 `PagingItemReader`의 클래스엔 다음과 같은 주석이 있는 것을 확인할 수 있다.

<br/> 

**`Setting a fairly large page size and using a commit interval that matches the page size should provide better performance.`**

<br/>

결국 청크사이즈와 일치하는 페이지 크기를 사용하면 성능향상을 기대할 수 있다는 말이다. 이외에도 JPA와 함께 사용할 경우 영속성 컨텍스트관련 이슈또한 만날 수 있다.

### JPA 영속성이슈 with PagingItemReader

JPA의 경우 `EntityManager`를 통해 엔티티들의 영속성을 관리해주며 이 과정은 당연히 배치에도 적용이 된다. 다음의 코드를 보자.

```java
@Configuration
@RequiredArgsConstructor
public class JobInstConfiguration {

    private final JobBuilderFactory jobBuilderFactory;
    private final StepBuilderFactory stepBuilderFactory;
    private final EntityManagerFactory emf;

    private int chunk_size = 100;

    @Bean
    public Job batchJob1() {
        return jobBuilderFactory.get("batchJob1")
                .start(step1())
                .build();
    }

    @Bean
    public Step step1() {
        return stepBuilderFactory.get("step1")
                .<Customer, History>chunk(chunk_size)
                .reader(customItemReader())
                .processor(customProcessor())
                .writer(customItemWriter())
                .build();
    }

    @Bean
    public ItemReader<Customer> customItemReader() {

        Map<String, Object> params = new HashMap<>();
        params.put("firstName", "A%");

        return new JpaCursorItemReaderBuilder<Customer>()
                .name("jpaCursorItemBuilder")
                .entityManagerFactory(emf)
                .queryString("select c from Customer c where firstname like :firstname")
                .parameterValues(params)
                .build();
                // 기본 페이지 사이즈는 10건
    }

    @Bean
    public ItemProcessor<Customer,History> customProcessor(){
        return customer -> History.builder()
            .customerId(customer.getId())
            .purchaseList(customer.getPurchaseList())
            .build()
    }

    @Bean
    public ItemWriter<History> customItemWriter() {
        return items -> {
            for (Customer item : items) {
                System.out.println(item);
            } // 그냥 출력만
        };
    }
}
```

청크사이즈는 100이며 페이지 사이즈는 10이므로 10번이 한번의 청크를 이룬다. 여기서
Customer과 History라는 도메인이 등장한다. History의 경우 기록용 클래스이므로 무시하고, Customer는 다음과 같은 필드를 가지고있다고 하자.

```java
@Entity
@Getter
@NoArgsConstructor
public class Customer {

    @Id @GeneratedValue
    private Long id;

    private String firstname;
    private String lastname;
    private String birthdate;

    @OneToMany
    private List<Purchase> purchaseList;
}
```

Purchase라는 새로운 도메인과 1:M매핑이 되어있다. 여기서 `reader`로부터 `processor`까지 넘어갈때 영속성이 유지되어야 해당 `@OneToMany`인 purchaseList속성이 History클래스로 매핑될 수 있다. **하지만 이 과정이 정말 잘 될까?**

<br/>

위와 같은 배치를 실제로 실행시켜보면 다음과 같은 오류를 만난다. 
`org.hibernate.LazyInitializationException: failed to lazily initialize a collection of role:~~` Processor의 Customer -> History로 transform 하는 과정중에 `getPurchaseList()`에서 LazyInitialize가 되지 않기 때문이다.

### 이유는?

기본적으로 위 이슈가 발현된 이유는 우리가 설정해준 `ChunkSize`와 `PageSize`가 다르기 때문이다.
> 위에서 **PageSize 조절하는 코드는 못봤는데요**? 라고 물을 수 있지만 `AbstractPagingItemReader<T>`를 확인하면 기본 `pageSize`는 10으로 되어있다. 이 값이 Default에 해당한다.

따라서 `JpaPagingItemReader`는 100의 `ChunkSize`를 채우기 위해 10개가 들어있는 페이지를 10번의 반복 진행하여 Chunk를 채우고 프로세스에게 넘겨주게 된다.

<br/>

`JpaPagingItemReader`의 `doReadPage()`메서드를 다시한번 확인하자.

```java
@Override
@SuppressWarnings("unchecked")
protected void doReadPage() {

	EntityTransaction tx = null;
	
	if (transacted) {
		tx = entityManager.getTransaction();
		tx.begin();
		
		entityManager.flush();
		entityManager.clear();
	}

	// ... 
```

이 메서드는 페이지 단위로 읽어올때 실행되는 일종의 Iteration되는 메서드에 해당한다. transaction의 상태를 측정하는 `transacted`의 값이 true일 경우 해당 로직으로 들어오게되는데, 이때 `entityManager.flush(); entityManager.clear();` 를 호출한다. **즉, 영속성 매니저를 초기화 시켜버린다는 것이다.** 

<br/>

따라서 마지막 페이지를 제외한 1~9 번째 페이지는 LazyLoading을 진행하지 못하게 된다. 
> 아예 프록시 객체도 꽂혀있지 않아 이러한 Exception이 발생되는 것이다.

하지만 마지막 10번째 페이지의 경우, entityManager가 살아있는 상태로 전달이 되므로 Processor에서 이에 대한 LazyLoading을 진행할 수 있다. (relation이 있는 프록시 객체가 꽂혀있다.)

### 해결방법

해결방법은 정말 단순하게도 `ChunkSize == PageSize`를 맞추어주는 것이다. 그 외에는 `AbstractPagingItemReader<T>`를 새로 상속하여 임의의 클래스를 만들어 직접 `entityManager`를 관리해주는 방법이 있다. 
> 엔티티매니저의 flush나 clear에 대한 시점을 직접 설정해야하는 것이다.

### 더 나아가면

LazyLoading을 진행하면 모든 `Customer`마다 연결되어있는 `Purchase`들의 Proxy를 깨워 해당 매핑을 완료지을 것이다. 이때 하나의 `Customer`당 `Purchase`개수만큼 SELECT쿼리를 날려 가져오는데, 이때 `spring.jpa.properties.hibernate.default_batch_fetch_size` 옵션을 주면 in query로 한번에 가져온다.
> fetch Join과 함께 대표적인 N+1 문제를 해결할 수 있는 솔루션이다.

> 이외에도 `@BatchSize`어노테이션을 주어도 된다.

### 더 나아가면 2

그러면 여기서 궁금증이 하나 든다, 
> 아니 생각해보니까 `JpaCursorItemReader`도 있잖아? 얘는 어떻게 영속성 유지를 하는거지?

사실 `JpaCursorItemReader`은 최근들어(스프링 배치 4.3) 도입된 클래스에 해당한다. 이 기능이 작동되게끔 하는 원리는 `doOpen()`메서드를 통해 보면 알 수 있다.


```java
@Override
@SuppressWarnings("unchecked")
protected void doOpen() throws Exception {
	this.entityManager = this.entityManagerFactory.createEntityManager();
	if (this.entityManager == null) {
		throw new DataAccessResourceFailureException("Unable to create an EntityManager");
	}
	if (this.queryProvider != null) {
		this.queryProvider.setEntityManager(this.entityManager);
	}
	Query query = createQuery();
	if (this.parameterValues != null) {
		this.parameterValues.forEach(query::setParameter);
	}
	this.iterator = query.getResultStream().iterator();
}

@Override
protected T doRead() {
	return this.iterator.hasNext() ? this.iterator.next() : null;
}
```

`doOpen()`의 마지막줄을 보면 `query.getResultStream()`을통해 resultStream을 뽑아낸다. jdbc의 ResultSet과 비슷한 개념으로, 이는 JPA에서도 데이터 스트림을 뽑아낸다는 것을 의미한다.
> 해당 기능은 JPA 2.2 이후부터 지원했다. 자세한 정보는 [여기](https://github.com/eclipse-ee4j/jpa-api/issues/99)에서 찾을 수 있다.

 
# 출처

- [기억보다 기록을 - Spring Batch에서 영속성 컨텍스트 문제](https://jojoldu.tistory.com/146?category=902551)
- [기억보다 기록을 - Spring Batch JpaCursorItemReader 도입되다](https://jojoldu.tistory.com/551)
- [Spring Batch 강의 - 정수원님](https://www.inflearn.com/course/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B0%B0%EC%B9%98) 