---
title: elk의 기본구조와 사용법
date: 2021-10-03 12:00:00 +0900
categories: [DevOps,elk]
tags: [elasticsearch,kibana,logstash,log]
---

## ELK

<img src="/assets/img/elk/1.png">

위 그림과 같이 분석 및 저장 기능을 담당하는 Elastic Search + 수집 기능을 하는 Logstash + 시각화 도구인 Kibana의 조합을 일컫는다.

1. Elastic Search
  - Lucene 기반의 분산 검색엔진에 해당한다. Logstash를 통해 수신된 데이터를 저장하는 역할을 담다안다.
  - (비)정형, 메트릭 등 원하는 방법으로 다양한 유형의 검색을 수행하고 결합할 수 있다
  - REST API를 사용해 CRUD요청을 보낼 수 있다. (RDB와 문법차이가 존재한다)

2. Log stash
  - 오픈소스 서버측 데이터 처리 파이프라인으로, 다양한 소스에서 동시에 데이터를 수집하고 변환하여 stash 보관소로 보내게된다.
  - 수집할 로그를 선정해서, 지정된 대상 서버(ElasticSearch)에 인덱싱 하여 전송하는 역할을 담당한다.

3. Kibana
 - 데이터를 시각적으로 탐색하고 실시간으로 분석할 수 있다. 
 - 시각화를 담당하는 HTML + JavaScript 엔진이라고 볼 수 있다.
 - 좀 살펴보니, 그라파나와 유사하다. kibana는 UI측면을 강화한 특징이 있다.

---

### 본체인 ElasticSearch란? [출처](https://esbook.kimjmin.net/03-cluster/3.1-cluster-settings)

#### 1. 클러스터 구조

항상 클러스터를 기본으로 동작을하며, 1개의 노드만 존재해도 클러스터로 구성이된다. 각각의 노드들은 클라이언트와의 통신을 위한 http     포트와 노드간의 데이터 교환을 위한 tcp포트 2개의 네트워크 통신을 열어두게 된다.!
> 일반적으로 1개의 물리서버마다 하나의 노드 실행을 권장하고 있다. (하나의 물리서버 안에서 여러개의 노드 실행도 가능하다)

> 이 옵션은 Elasticsearch 시작옵션에 줄 수 있으며 클러스터 이름과 포함된 노드 이름들을 넣어줄 수 있다.

#### 2. 디스커버리

노드가 처음 실행 될때 같은 서버 또는 네트워크 상의 다른 노드들을 찾아 하나의 클러스터로 바인딩하는 과정을 디스커버리라고 한다. `discovery.seed_hosts` 설정에 있는 주소 순서대로 노드가 있는지 여부를 확인하고, 클러스터명이 동일한 경우 같은 클러스터로 바인딩하게된다.

#### 3. 인덱스 & 샤드

단일 데이터 단위를 도큐먼트(document)라고 하며 이 도큐먼트를 모아놓은 집합을 인덱스라고 한다. 이러한 인덱스는 기본저으로 샤드(shard)라는 단위로 분리되고 각 노드에 분산되어 저장이 된다. 이 샤드는 루씬의 단일 검색 인스턴스에 해당한다. 만약 인덱스를 설정할 때 별도의 설정을 주지 않는다면 7버전 이후부터는 디폴트로 1개의 샤드로 인덱스가 구성된다. 이 샤드의 개수는 인덱스를 처음 생성할때 지정할 수 있으며 재색인(reindexing)이 아니라면 바꿀 수 없다.
> 즉 샤드는 ElasticSearch가 데이터를 클러스터 내에 분산 저장하기 위한 단위에 해당하며 이는 루씬의 인덱스라고 보면 된다.

만약 노드 1개에 샤드의 개수를 2개로 설정하고, 6개의 도큐먼트를 저장하게 되면 아래와 같이 저장된다.

<img src="/assets/img/elk/2.png">

데이터의 개수가 작다면 1개정도로 유지하는 것이 좋지만 크기가 크다면 목표응답속도에 부합하게 증가시키는 것이 좋다. 샤드는 데이터를 분산 저장하는 역할도 있지만, 분산하여 검색을 진행하므로 이 개수가 많을 수록 쿼리 속도는 빨라지게 된다. 하지만 쿼리를 수행하면 샤드의 개수만큼 CPU의 스레드를 사용하기 때문에 리소스를 많이 잡아먹게 된다.

#### 3.1 프라이머리 샤드 & 레플리카

클러스터에 노드를 추가하게 되면 샤드들이 각 노드들로 분산되고 디폴트로 1개의 복제본을 생성하게 된다. 여기서 처음 생성된 샤드를 프라이머리 샤드라고하며 복제본은 레플리카라고 이야기한다. 
> 예를들어 한 인덱스가 5개의 샤드로 구성되어 있고, 클러스터가 4개의 노드로 구성되어 있다고 가정하면 각각 4개의 프라이머리 샤드와 복제본인 10개의 샤드들이 전체 노드에 골고루 분배되어 저장된다.

> 샤드와 복제본은 동일한 데이터를 담고 있으며 반드시 서로 다른 노드에 저장된다. 이는 노드 하나가 사라지더라도 데이터의 유실을 방지하기 위함이다. 유실된 노드가 복구되지 않는다고 판단되면 1개만 남은 샤드들의 복제를 시작해 남은 노드에 분산저장한다.

#### 4. 마스터노드 & 데이터노드

클러스터는 하나이상의 노드들로 이루어지는데, 이 중 하나의 노드는 인덱스의 메타 데이터, 샤드의 위치와 같은 클러스터 상태정보를 관리하는 마스터노드의 역할을 수행한다. 클러스터마다 1개씩 존재하며 이 역할을 수행할 수 있는 노드가 없다면 클러스터는 작동이 정지된다.
> 키바나에서 별로 표현된 노드가 마스터노드에 해당한다.

<br/>

설치 이후, 기본 정보가 들어있는 elasticsearch.yml을 살펴보면 디폴트 설정은 `node.master: true`로 되어있는데 이는 기본적으로 모든 노드가 마스터 노드로 선출될 수 있음을 의미한다. 현재 마스터 역할을 수행하는 노드가 다운되면 다른 노드중 하나가 선출되어 대신 수행하게 된다. 후보 노드들은 처음부터 마스터노드의 정보를 공유하고 있기에, 즉시 역할 수행이 가능하다.
> 클러스터가 커지면 이 설정은 부담스러울 수 있다. 모든 노드가 해당 정보를 공유하기 때문이다. 따라서 이럴때에는 false로 설정값을 바꾸자.

<br />

데이터노드는 실제로 인덱싱된 데이터를 저장하고 있는 노드에 해당한다. 클러스터에서 마스터 노드와 데이터 노드를 분리하여 설정 할 때 마스터 후보 노드들은 `node.data: false` 로 설정하여 마스터 노드 역할만 하고 데이터는 저장하지 않도록 할 수 있다.
> 이렇게 되면 마스터 노드는 데이터를 저장하지 않고 클러스터 관리만 하게 되고, 데이터 노드는 클러스터 관리 작업으로부터 자유롭게 되어 데이터 처리에만 집중할 수 있다.

---

### 어떻게 사용하는지 확인해보자.. [officialdocs](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)가 잘되어있어 이곳의 도움을 많이 받았다.

맥 환경에서 brew install을 이용해 ElasticSearch를 다운로드 받아야 한다. 완료되었다면 다음과 같이 curl을 보내 체크해보았다.

<img src="/assets/img/elk/4.png">

default조건에서는 9200포트에서 실행이 되고 버전정보가 나와있다. 여기까지는 OK.. 뭔가 이전의 Rabbit MQ를 쓸때의 느낌같다. 가장먼저 상위 키워드인 인덱스에 접근을 해보겠다.

`curl -XGET http://localhost:9200/classes`
> classes라는 인덱스가 존재하는지 확인해보는 것이다. 당연히 없으므로 error를 뱉을 것이다.

<img src="/assets/img/elk/5.png">

역시.. 404 notfoundindex가 나오고 있다. 직접 생성을 해주겠다.`curl -XPUT http://localhost:9200/vitriol`
>  이후 직접 확인을 하면 다음과 같이 응답값을 받는다.

<img src="/assets/img/elk/6.png">

지우는 것은 DELETE를 통해 가능하다 `curl -XDELETE http://localhost:9200/vitriol` 정상적으로 지워졌다면 acknowledged true를 받는다.

---

#### Document의 CRUD API

elastic search에서 제공하는 Index관련 API는 다음과 같다.
> 입력(PUT), 조회(GET), 삭제(DELETE), 수정(POST)을 각각의 http메서드와 매칭시켜야한다. 특이한점은 입력과 수정이다.

<img src="/assets/img/elk/7.png">

지금과 같이 인덱스만 존재하고 아무런 document가 없을때, 세번째 명령을 통해 새 document를 추가할 수 있다. 첫번째 명령의 경우에는 존재하는 ID를 가진 document를 변경할 수 있다. (두번째 명령의 경우는 임의의 ID가 생성이된다)
> 새롭게 document를 생성해보자. 앞으로는 키바나 콘솔을 이용해 진행할 예정이다.

<img src="/assets/img/elk/8.png">


GET 요청을 통해 이렇게 가져오는 것도 당연히 가능하다. 굉장히 Handy하다. Update도 진행해보자. 동일한 URL에 다른 내용의 도큐먼트를 다시 입력하게 되면 기존 도큐먼트는 삭제되고 새로운 도큐먼트로 덮어씌워지게 된다.!

<img src="/assets/img/elk/9.png">


위와 같이 results란에 update로 뜨게된다. put을 사용하였고 이는 '입력'에 해당하므로 해당 도큐먼트를 그대로 덮어쓰게 된다. 만약 필드를 추가하고 싶은 경우는 어떻게 해야할까
<br/>

`POST <인덱스>/_update/<_id>` 문법을 사용해야한다. 앞서 이야기 하였듯 수정에 POST가 쓰이는 것을 잘 보아야한다. 하나의 필드를 업데이트 시켜보겠다.

<img src="/assets/img/elk/10.png">

다음과 같이 doc{}안에 감싸주어 전달해주어야한다. 우리는 document를 수정할 것이기 때문이다. (이와 관련된 이야기는 뒷부분에 좀 더 다룰 수 있겠다. 이말은 document 말고도 다른 설정들을 건드릴 수 있다는 것이다.)

프로그래밍을 이용해 업데이트 시키는 방법또한 존재한다.

<img src="/assets/img/elk/11.png">

다음과 같이 age를 5 증가시키는 스크립트를 보내게 되면

<img src="/assets/img/elk/12.png">

다음과 같이 26이 되어있다. 동적으로 업데이팅할때 사용하면 되겠다.

---

#### Bulk API

여러개의 명령을 배치로 수행하기 위해서 Bulk API또한 지원하고 있다. delete를 제외하고는 명령문과 데이터문을 한줄씩 순서대로 입력해야한다. (delete는 내용 입력이 필요없기에 명령문만 존재한다.)

<img src="/assets/img/elk/13.png">

위와 같이 입력할 경우 test/_doc/1, test/_doc/2 에 field값이 입력되며 test/_doc/2 도큐먼트를 삭제한다. 이후 3번에 새로운 도큐먼트를 입력하고 1번 도큐먼트를 수정하게 된다.

<br/>
모든 명령이 동일한 인덱스에서 수행되는 경우에는 <인덱스명>/_bulk 형식으로도 가능하다. 이때는 명령문에 _index 항목이 필요가 없다.
> bulk 동작은 SQL DB와 마찬가지로 따로따로 수행할때보다 속도가 빠르다. 불필요한 오버헤드를 줄여준다.!

<br/>
이를 파일화한것을 전달할 수도 있다. 
`curl -XPOST "http://localhost:9200/_bulk" -H 'Content-Type: application/json' --data-binary @bulk.json` 라고 보내면 현 위치에 존재하는 bulk.json 파일을 보내게된다.

---

#### Search API (명령어는 [이곳](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html)에 잘 나와있다.)

Elastic Search를 사용하는 가장 큰 이유가 아닐까 싶다. GET <인덱스명>/_search 형식으로 사용하게 되며 쿼리를 입력하지 않으면 전체 도큐먼트를 찾는 match_all 검색을 수행하게 된다.

1. 쿼리 스트링 이용하기

가장 먼저 전체검색을 수행해보자.

<img src="/assets/img/elk/14.png">

`hits.total.value`에 검색결과 전체에 해당되는 문서 개수가 표시가 되고, 다시 그 안의 hits:[]안에 정확도가 높은 문서가 나타난다.
여기서 value1을 검색해보자.

<img width="254" alt="image" src="/assets/img/elk/15.png">

오.. value1을 가지고 있는 항목에 대해 hits:[]에 잘 나와있다. 여기에 보면 아이디값과 더불어 score가 주어져 있는데 이는 나중에 이야기해보겠다(이를 relevancy 라고 한다). 다음과 같이 조건 연산자도 가능하다

`GET test/_search?q=value1 AND value2` 이 경우, value1과 2를가진 자료만 가져올 것이다.
> AND, OR, NOT의 사용이 가능하며 반드시 대문자로 입력해야 한다.

검색어 value를 field에서 찾고 싶다면 <필드명>:<검색어>형태로 입력해주면 된다. 

<img src="/assets/img/elk/16.png">


2. 데이터 바디를 이용한 검색

검색 쿼리를 데이터 본문으로 입력하는 방식에 해당한다. elasticSearch의 queryDSL을 사용하며 쿼리 또한 Json형태로 이루어져 있다. 가장 쉽고 많이 사용되는 명령어는 match쿼리에 해당한다. field필드값이 value인 도큐먼트를 검색하기 위해서는 다음과 같은 명령을 주면된다.

<img src="/assets/img/elk/17.png">

> 쿼리 입력은 항상 query지정자로 시작하며 그 다음레벨에서 쿼리 종류를 지정하는데 match를 지정했다. 그 다음은 종류에 따라 다른 입력값이 들어오는데, match쿼리는 <필드명>:<검색어> 방식으로 입력한다.

3. 멀티테넌시(Multitenancy)

여러개의 인덱스를 한꺼번에 묶어서 검색 할 수 있는 멀티테넌시를 지원한다. `logs-2021-07`,`logs-2021-08`과 같이 날짜별로 저장된 인덱스들이 있다면 이 인덱스들을 모두 `logs-*/_search` 명령어로 한거번에 검색이 가능하다.
> 여러 인덱스를 검색할 때는 쉼표로 나열하거나 와일드카드로 묶어버릴 수 있다.

4. 주로 사용되는 쿼리들

##### 풀 텍스트 쿼리(Full Text Query)

- match: 가장 일반적인 쿼리로 다음은 match를 이용해 message 필드에 quick 혹은 dog이 포함되는 모든 문서를 검색한다.

<img src="/assets/img/elk/18.png">


> 이처럼 단어를 나열하게 되면 디폴트로 OR조건으로 검색이 되어 입력된 검색어별로 하나라도 포함된 모든 문서를 검색한다.

<img src="/assets/img/elk/19.png">

> 이를 And로 바꾸는 것은 operator 옵션을 만져주면 된다. quick과 dog이라는 단어가 포함된 도큐먼트들만 검색이 된다.

- match_phrase

정확히 일치하는 ('lazy dog' 이라는 단어가 있는)것을 검색하고 싶다면 match_phrase 명령어를 사용하면 된다. 

<img src="/assets/img/elk/20.png">

> 정확히 'lazy dog'이라는 문구가 있는 도큐먼트들만 검색해준다.

- query_string

아예 쿼리스트링을 메시지 바디 안으로 넣어 루씬의 검색 문법으로 사용할 수 있다. 다음은 message라는 필드에서 lazy와 jumping을 포함하거나 quick dog 구문을 포함하는 도큐먼트를 검색하는 쿼리에 해당한다. 구문 검색을 진행할 경우는 쌍따옴표 \" 안에 넣어야한다.

<img src="/assets/img/elk/21.png">

와.. 이정도까지 해보니 어떻게 사용해야하고, 키워드를 주어야하는지 알 것 같다. (docs를 보고 아 이렇게 하는 거구나.. 하는 수준?) 하나만 더해보자. bool값을 이용한 복합쿼리 작성이다.

##### Bool Query

앞선 query_string 쿼리는 여러 조건을 조합하기에 용이하지만 옵션이 한정되어있다. 본문 검색에서 여러 쿼리를 조합하기 위해서는 상위에 bool 쿼리를 이용하고 그 안에 다른 쿼리들을 넣는 식으로 사용이 가능하다. bool 쿼리는 다음의 4개의 인자를 가진다.

- must: 쿼리가 참인 도큐먼트를 검색
- must_not: 쿼리가 거짓인 도큐먼트를 검색
- should: 검색 결과 중 이 쿼리에 해당하는 도큐먼트의 점수를 높인다.
- filter: 쿼리가 참인 도큐먼트를 검색하지만 스코어를 계산하지 않는다. must보다 검색 속도가 빠르고 캐싱이 가능하다.

###### 예시 1) - quick과 lazy dog가 포함된 모든 도큐먼트를 검색하기

<img src="/assets/img/elk/22.png">

###### 예시 2) - quick과 lazy dog이 하나도 포함되지 않는 도큐먼트 검색

<img src="/assets/img/elk/23.png">

BOOL 쿼리의 must, should등은 SQL의 AND,OR과 유사하지만 정확히 같지는 않다. 표준 SQL의 and or 조건은 값에 대한 이항 연산을 진행하지만, must나 should의 경우는 내부에 있는 각각의 쿼리들에 대해 참또는 거짓으로 작용하는 단항 연산자에 해당한다.

<img src="/assets/img/elk/24.png">

---

#### Relevancy

RDBMS와의 가장 큰 차이점을 제공하는 파라미터에 해당한다. 각 결과들이 얼마나 정확한지에 대한 판단은 불가능하므로, elasticsearch와 같은 풀 텍스트 검색엔진은 조건과 얼마나 정확하기 일치하는지를 계산하는 알고리즘이 있어 이 정확도를 기반으로 결과를 먼저 보여줄 수 있다.

<br/>
그렇게 되면 어떠한 알고리즘을 쓰는지가 가장 궁금하다. BM25라는 알고리즘을 사용한다고 하는데, 이의 식은 다음과 같다. 

<img src="/assets/img/elk/25.png">

위키피디아를 참고하여 이야기해보자면 쿼리에 있는 용어가 각각의 문서에 얼마나 자주 등장하는지를 평가한다. 키워드 q1...qn을 포함하는 쿼리 Q가 주어질 때 문서 D에 대한 점수를 계산하는 식에 해당한다. 

- IDF(q_i)의 경우에는 쿼리 i번째 토큰에 대한 inverse document frequency로 자주 등장하는 단어를 penalize하여 높은 가중치를 막는다.
> 예를들면.. 관사중 the 같은것이 있을 수 있다.

- abs(D)/avgdl 는 문서 길이에 대한 가중치에 해당한다. 점수 계산에 있어서 분모에 있기 때문에 평균 대비 긴 문서는 penalize됨을 알 수 있다.

- 나머지 b나 k1같은 경우는 파라미터에 해당한다.

> 은근 직관적인 식이다. 결국 Term Frequency를 계산하고 이에 대해 키워드별로 IDF곡선을 타 감쇄시켜준뒤 length fraction과 반비례하게 점수를 나타내준다.

<br/>

앞서 사용하지 못한 bool 연산자인 should를 써보자. 먼저 match 쿼리로 fox를 포함하고 있는 도큐먼트를 검색하고, 이 결과들 중 lazy가 포함된 결과에 가중치를 줘서 상위로 올리는 시나리오에 해당한다.

<img src="/assets/img/elk/26.png">

<br/>

<img src="/assets/img/elk/27.png">

앞선 BM25과 점수를 보면 딱 이해가 된다. 두번째와 세번째는 길이가 같고 TF가 같으니 같은 점수를 얻었지만, 아래는 길이가 더 길기때문에 낮은 점수를 가지고 있었다.
> 대단한데 이거...

## 출처 (https://esbook.kimjmin.net/01-overview/1.1-elastic-stack) 

정말 큰 도움되었습니다 감사합니다.!

